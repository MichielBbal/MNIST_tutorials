{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dit notebook maken en trainen we een autoencoder voor de `mnist` dataset.\n",
    "We gebruiken deze vervolgens om nieuw afbeeldingen van handgeschreven letters te genereren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De code in dit voorbeeld is gebaseerd op de code uit hoofdstuk 3 van *Generative Deep Learning* van David Forester, O'Reilly Media, 2019 en op hoofdstuk 8 van *Deep Learning with Python* door François Chollet, Manning, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, Reshape, Lambda, Activation, BatchNormalization, LeakyReLU, Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### verover de data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_train = x_train.reshape(x_train.shape + (1,))\n",
    "    \n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_test = x_test.reshape(x_test.shape + (1,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afbeeldingen zijn 28x28 pixels in zwart/wit (1 kanaal).\n",
    "\n",
    "We projecteren iedere afbeelding naar 2 getallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (28, 28, 1)\n",
    "z_dim = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We maken eerst een `encoder`. We maken hiervoor gebruik van de functionele notatie van Keras. De `encoder` is in essentie een CNN dat een afbeelding terugbrengt tot twee getallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(input_dim, name = 'encoder_input')\n",
    "\n",
    "x = Conv2D(filters = 32,\n",
    "           kernel_size = 3,\n",
    "           padding = 'same',\n",
    "           name = 'encoder_conv_1')(encoder_input)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 64,\n",
    "           kernel_size = 3,\n",
    "           strides = (2,2),\n",
    "           padding = 'same',\n",
    "           name = 'encoder_conv_2')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 64,\n",
    "           kernel_size = 3,\n",
    "           strides = (2,2),\n",
    "           padding = 'same',\n",
    "           name = 'encoder_conv_3')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2D(filters = 64,\n",
    "           kernel_size = 3,\n",
    "           padding = 'same',\n",
    "           name = 'encoder_conv_4')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "shape_before_flattening = K.int_shape(x)[1:]\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "encoder_output = Dense(z_dim, name = 'encoder_output')(x)\n",
    "\n",
    "encoder = Model(encoder_input, encoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestudeer bovenstaande code en maak vervolgens een `summary` van het model. Komt deze samenvatting overeen met jouw verwachtingen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu maken we een `decoder`. Deze vertaalt een representatie bestaande uit twee getallen naar een afbeelding.\n",
    "Hiervoor gebruiken we `Conv2DTranspose` lagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input((z_dim,), name = 'decoder_input')\n",
    "\n",
    "x = Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "x = Reshape(shape_before_flattening)(x) # van een dense vector naar de vorm van een afbeelding\n",
    "\n",
    "x = Conv2DTranspose(filters = 64,\n",
    "                kernel_size = 3,\n",
    "                padding = 'same',\n",
    "                name = 'decoder_conv_t_1')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(filters = 64,\n",
    "                kernel_size = 3,\n",
    "                strides = (2,2),\n",
    "                padding = 'same',\n",
    "                name = 'decoder_conv_t_2')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(filters = 32,\n",
    "                kernel_size = 3,\n",
    "                strides = (2,2),\n",
    "                padding = 'same',\n",
    "                name = 'decoder_conv_t_3')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "x = Conv2DTranspose(filters = 1,\n",
    "                kernel_size = 3,\n",
    "                padding = 'same',\n",
    "                name = 'decoder_conv_t_4')(x)\n",
    "x = LeakyReLU()(x)\n",
    "\n",
    "decoder_output = Activation('sigmoid')(x)\n",
    "\n",
    "decoder = Model(decoder_input, decoder_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestudeer bovenstaande code en maak vervolgens een `summary`. Merk op dat de output van de laatste laag de afmetingen heeft van een afbeelding uit de `mnist` dataset. De `decoder` is een gespiegelde versie van de `encoder`, dit is echter niet noodzakelijk, de enige eis is dat het netwerk op basis van twee getallen een afbeelding kan genereren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De volledige autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De autoencoder koppelt de `encoder` en de `decoder`. Door deze samen te trainen en als loss functie de *mean squared error* tussen de originele afbeelding (input van de encoder) en de output van de decoder te nemen, optimaliseert de autoencoder de gewichten van beide onderdelen voor het reconstrueren van afbeeldingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(encoder_input, decoder(encoder_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compileer en train de `autoencoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "\n",
    "optimizer = Adam(learning_rate = learning_rate)\n",
    "\n",
    "def r_loss(y_true, y_pred):\n",
    "    return K.mean(K.square(y_true - y_pred), axis = [1,2,3])\n",
    "\n",
    "autoencoder.compile(optimizer = optimizer, loss = r_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merk op dat in onderstaande code de labels gelijk zijn aan de inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = 3000\n",
    "\n",
    "autoencoder.fit(x = x_train[:subset], y = x_train[:subset], batch_size = 32, epochs = 20, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Reconstructie van originele afbeeldingen\n",
    "\n",
    "Laten we nu eens kijken wat voor resultaten de `autoencoder` oplevert. Om te beginnen kijken we hoe goed de `decoder` in staat is om afbeeldingen te reconstrueren.\n",
    "\n",
    "We selecteren willekeurige afbeeldingen uit de testset, coderen deze met de `encoder` en decoderen deze met de `decoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10\n",
    "\n",
    "# selecteer willekeurige afbeeldingen uit x_test\n",
    "idx = np.random.choice(range(len(x_test)), n)\n",
    "test_images = x_test[idx]\n",
    "\n",
    "# vertaal met de encoder naar getallen\n",
    "z_points = encoder.predict(test_images)\n",
    "\n",
    "# vertaal de getallen met de decoder terug naar afbeeldingen\n",
    "reconstr_images = decoder.predict(z_points)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 3))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(n):\n",
    "    img = test_images[i].reshape((28,28))\n",
    "    ax = fig.add_subplot(2, n, i + 1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, str(np.round(z_points[i],1)), fontsize=10, ha='center', transform=ax.transAxes)   \n",
    "    ax.imshow(img, cmap='gray_r')\n",
    "    \n",
    "for i in range(n):\n",
    "    img = reconstr_images[i].reshape((28,28))\n",
    "    ax = fig.add_subplot(2, n, i + n + 1)\n",
    "    ax.axis('off')\n",
    "    ax.imshow(img, cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bovenstaande plot laat op de bovenste rij de originele afbeeldingen zien en daaronder telkens de door de decoder gereconstrueerde afbeelding.\n",
    "\n",
    "Wat valt je op aan de reconstructies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om een beter beeld te krijgen van het gedrag van de autoencoder, plotten we de outputs van de encoder (de 'z-waarden') voor een deel van de testset. De kleur van een punt geeft het correcte label weer.\n",
    "\n",
    "Daarnaast selecteren we alvast een aantal willekeurige punten (dus een combinatie van twee willekeurige getallen) die we dadelijk gaan gebruiken om volledig nieuwe afbeeldingen te genereren. Deze punten worden in het rood weergegeven."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "grid_size = 10\n",
    "grid_depth = 3\n",
    "figsize = 12\n",
    "\n",
    "example_idx = np.random.choice(range(len(x_test)), n)\n",
    "test_images = x_test[example_idx]\n",
    "test_labels = y_test[example_idx]\n",
    "\n",
    "z_points = encoder.predict(test_images)\n",
    "\n",
    "min_x = min(z_points[:, 0])\n",
    "max_x = max(z_points[:, 0])\n",
    "min_y = min(z_points[:, 1])\n",
    "max_y = max(z_points[:, 1])\n",
    "\n",
    "plt.figure(figsize = (figsize, figsize))\n",
    "plt.scatter(z_points[:, 0] , z_points[:, 1] , cmap = 'rainbow' , c = test_labels, alpha = 0.5, s = 2)\n",
    "plt.colorbar()\n",
    "\n",
    "# willekeurige punten\n",
    "x = np.random.uniform(min_x,max_x, size = grid_size * grid_depth)\n",
    "y = np.random.uniform(min_y,max_y, size = grid_size * grid_depth)\n",
    "z_grid = np.array(list(zip(x, y)))\n",
    "\n",
    "plt.scatter(z_grid[:, 0] , z_grid[:, 1], c = 'red', alpha=1, s=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat valt je op aan bovenstaande plot met betrekking tot de verdeling van de labels?\n",
    "\n",
    "Wat valt je op aan bovenstaande plot met betrekking tot de willekeurig geselecteerde punten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gebruiken nu de `decoder` om op basis van de willekeurig gegenereerde punten volledig nieuwe afbeeldingen te genereren en plotten deze afbeeldingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconst = decoder.predict(z_grid)\n",
    "\n",
    "figsize = 15\n",
    "fig = plt.figure(figsize=(figsize, grid_depth))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "for i in range(grid_size*grid_depth):\n",
    "    ax = fig.add_subplot(grid_depth, grid_size, i+1)\n",
    "    ax.axis('off')\n",
    "    ax.text(0.5, -0.35, str(np.round(z_grid[i],1)), fontsize=10, ha='center', transform=ax.transAxes)\n",
    "    \n",
    "    ax.imshow(reconst[i, :,:,0], cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat valt je op aan deze afbeeldingen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varieer nu eens met het aantal lagen en filters in de `encoder` en `decoder`. Kun je de `decoder` een volledig andere vorm geven dan de `encoder`? Hoe beïnvloed dit het resultaat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-metal",
   "language": "python",
   "name": "tf-metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
